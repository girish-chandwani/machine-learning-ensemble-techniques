{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble method and Grid search with Cross_validation .\n",
    "\n",
    "In this Notebook, the main objective is to understand the parameters of the Decision Tree model and how to evaluate the model based on the different metrics we studied.\n",
    "\n",
    "By the end of this Notebook you should have:\n",
    "\n",
    "- a good understanding of ensemble of Decision Trees.\n",
    "- learn and implement how grid search and cross validation are combined in the GridsearchCV class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "- Using nested loops and split ratio 65_training, 15_validation, and 20_testing; while using only the training and validation sets build a random forest with number of trees between 5 and 12 with a step of 2 using the default parameters and implement a cross-validation with 4 folds. Ensure to print out the validation score for each fold and find the one that provides the best accuracy.\n",
    "\n",
    "- Once you have identified the one with the best accuracy above, evaulate the accuracy of this model using the testing_set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "### Importing packages\n",
    "##### - Numpy packages are used to work on array\n",
    "##### - Pandas packages are used for working on dataframes while fetching the data from csv and while creating features and target dataframe for Machine learning models.\n",
    "##### - Matplotlib packages are used for plotting/visualing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import standard packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "### Importing data from file\n",
    "##### - using read_csv() function of pandas to fetch the data from our csv file into a dataframe.\n",
    "##### - our dataset is of customer churn data of a telecom company, based on various characteristics we can predict whether the customer will leave or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>phone number</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>...</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>382-4657</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>371-7191</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>358-1921</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>375-9999</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>330-6626</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  account length  area code phone number international plan  \\\n",
       "0    KS             128        415     382-4657                 no   \n",
       "1    OH             107        415     371-7191                 no   \n",
       "2    NJ             137        415     358-1921                 no   \n",
       "3    OH              84        408     375-9999                yes   \n",
       "4    OK              75        415     330-6626                yes   \n",
       "\n",
       "  voice mail plan  number vmail messages  total day minutes  total day calls  \\\n",
       "0             yes                     25              265.1              110   \n",
       "1             yes                     26              161.6              123   \n",
       "2              no                      0              243.4              114   \n",
       "3              no                      0              299.4               71   \n",
       "4              no                      0              166.7              113   \n",
       "\n",
       "   total day charge  ...  total eve calls  total eve charge  \\\n",
       "0             45.07  ...               99             16.78   \n",
       "1             27.47  ...              103             16.62   \n",
       "2             41.38  ...              110             10.30   \n",
       "3             50.90  ...               88              5.26   \n",
       "4             28.34  ...              122             12.61   \n",
       "\n",
       "   total night minutes  total night calls  total night charge  \\\n",
       "0                244.7                 91               11.01   \n",
       "1                254.4                103               11.45   \n",
       "2                162.6                104                7.32   \n",
       "3                196.9                 89                8.86   \n",
       "4                186.9                121                8.41   \n",
       "\n",
       "   total intl minutes  total intl calls  total intl charge  \\\n",
       "0                10.0                 3               2.70   \n",
       "1                13.7                 3               3.70   \n",
       "2                12.2                 5               3.29   \n",
       "3                 6.6                 7               1.78   \n",
       "4                10.1                 3               2.73   \n",
       "\n",
       "   customer service calls  churn  \n",
       "0                       1  False  \n",
       "1                       1  False  \n",
       "2                       0  False  \n",
       "3                       2  False  \n",
       "4                       3  False  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www.kaggle.com/becksddf/churn-in-telecoms-dataset/data\n",
    "#importing the dataset as dataframe\n",
    "churn_data = pd.read_csv(\"customer_churn.csv\")\n",
    "\n",
    "#Top 5 records of dataset\n",
    "churn_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating 1000 random index to select 1000 random samples from our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "#Index for random 1000\n",
    "idx = np.random.randint(3334, size=1000)\n",
    "print(len(idx))\n",
    "#print(idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "### Creating feature and target dataframes\n",
    "\n",
    "* We will create our feature and target dataframes using following steps\n",
    "    -  Select categorical feature and convert it into numeric\n",
    "    -  Select the other important numeric features and dropping less important one\n",
    "    -  Concatinating the converted categorical numeric value with feature to create feature dataframe\n",
    "    -  Creating the target dataframe, by converting it into numeric binary class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A) Select categorical feature and convert it into numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>international plan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   international plan\n",
       "0                   0\n",
       "1                   0\n",
       "2                   0\n",
       "3                   1\n",
       "4                   1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing LabelEncode from sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#Creating label encoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "#fitting nd transforming categorical feature into label encoder\n",
    "ip = le.fit_transform((churn_data[['international plan']].values.ravel()).astype('str'))\n",
    "#print(len(ip))\n",
    "ip\n",
    "\n",
    "#creating data frame after transformtion\n",
    "df1 = pd.DataFrame(ip, columns = [\"international plan\"])\n",
    "df1.head()\n",
    "#print(df1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) Select the other important numeric features and dropping less important one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "df = churn_data[['number vmail messages','total day minutes','total day calls','total day charge','total eve calls','total eve charge','total night minutes','total night calls','total night charge','total intl minutes','total intl calls','total intl charge','customer service calls']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C) Concatinating the converted categorical numeric value with feature to create feature dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3333, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>international plan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number vmail messages  total day minutes  total day calls  \\\n",
       "0                     25              265.1              110   \n",
       "1                     26              161.6              123   \n",
       "2                      0              243.4              114   \n",
       "3                      0              299.4               71   \n",
       "4                      0              166.7              113   \n",
       "\n",
       "   total day charge  total eve calls  total eve charge  total night minutes  \\\n",
       "0             45.07               99             16.78                244.7   \n",
       "1             27.47              103             16.62                254.4   \n",
       "2             41.38              110             10.30                162.6   \n",
       "3             50.90               88              5.26                196.9   \n",
       "4             28.34              122             12.61                186.9   \n",
       "\n",
       "   total night calls  total night charge  total intl minutes  \\\n",
       "0                 91               11.01                10.0   \n",
       "1                103               11.45                13.7   \n",
       "2                104                7.32                12.2   \n",
       "3                 89                8.86                 6.6   \n",
       "4                121                8.41                10.1   \n",
       "\n",
       "   total intl calls  total intl charge  customer service calls  \\\n",
       "0                 3               2.70                       1   \n",
       "1                 3               3.70                       1   \n",
       "2                 5               3.29                       0   \n",
       "3                 7               1.78                       2   \n",
       "4                 3               2.73                       3   \n",
       "\n",
       "   international plan  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   1  \n",
       "4                   1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatinating data with categorical feature converted to numeric\n",
    "df = pd.concat([df, df1], axis=1, sort=False)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting 1000 random features based on the 1000 random indexs that we created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>international plan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>0</td>\n",
       "      <td>256.4</td>\n",
       "      <td>125</td>\n",
       "      <td>43.59</td>\n",
       "      <td>100</td>\n",
       "      <td>23.28</td>\n",
       "      <td>222.7</td>\n",
       "      <td>101</td>\n",
       "      <td>10.02</td>\n",
       "      <td>11.1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>81</td>\n",
       "      <td>38.25</td>\n",
       "      <td>63</td>\n",
       "      <td>15.04</td>\n",
       "      <td>194.3</td>\n",
       "      <td>110</td>\n",
       "      <td>8.74</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>22</td>\n",
       "      <td>204.5</td>\n",
       "      <td>92</td>\n",
       "      <td>34.77</td>\n",
       "      <td>121</td>\n",
       "      <td>11.87</td>\n",
       "      <td>205.0</td>\n",
       "      <td>103</td>\n",
       "      <td>9.23</td>\n",
       "      <td>8.6</td>\n",
       "      <td>5</td>\n",
       "      <td>2.32</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>0</td>\n",
       "      <td>186.8</td>\n",
       "      <td>92</td>\n",
       "      <td>31.76</td>\n",
       "      <td>123</td>\n",
       "      <td>14.76</td>\n",
       "      <td>250.9</td>\n",
       "      <td>131</td>\n",
       "      <td>11.29</td>\n",
       "      <td>9.7</td>\n",
       "      <td>4</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>0</td>\n",
       "      <td>249.8</td>\n",
       "      <td>109</td>\n",
       "      <td>42.47</td>\n",
       "      <td>106</td>\n",
       "      <td>20.60</td>\n",
       "      <td>231.8</td>\n",
       "      <td>78</td>\n",
       "      <td>10.43</td>\n",
       "      <td>11.6</td>\n",
       "      <td>4</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>28</td>\n",
       "      <td>225.8</td>\n",
       "      <td>94</td>\n",
       "      <td>38.39</td>\n",
       "      <td>117</td>\n",
       "      <td>16.41</td>\n",
       "      <td>232.4</td>\n",
       "      <td>100</td>\n",
       "      <td>10.46</td>\n",
       "      <td>8.4</td>\n",
       "      <td>9</td>\n",
       "      <td>2.27</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>125.2</td>\n",
       "      <td>93</td>\n",
       "      <td>21.28</td>\n",
       "      <td>119</td>\n",
       "      <td>17.54</td>\n",
       "      <td>129.3</td>\n",
       "      <td>139</td>\n",
       "      <td>5.82</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>35</td>\n",
       "      <td>161.9</td>\n",
       "      <td>85</td>\n",
       "      <td>27.52</td>\n",
       "      <td>82</td>\n",
       "      <td>12.85</td>\n",
       "      <td>191.0</td>\n",
       "      <td>131</td>\n",
       "      <td>8.59</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2315</th>\n",
       "      <td>0</td>\n",
       "      <td>150.7</td>\n",
       "      <td>52</td>\n",
       "      <td>25.62</td>\n",
       "      <td>96</td>\n",
       "      <td>20.97</td>\n",
       "      <td>103.8</td>\n",
       "      <td>118</td>\n",
       "      <td>4.67</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.89</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>0</td>\n",
       "      <td>150.1</td>\n",
       "      <td>120</td>\n",
       "      <td>25.52</td>\n",
       "      <td>85</td>\n",
       "      <td>17.01</td>\n",
       "      <td>266.7</td>\n",
       "      <td>105</td>\n",
       "      <td>12.00</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.97</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      number vmail messages  total day minutes  total day calls  \\\n",
       "454                       0              256.4              125   \n",
       "243                       0              225.0               81   \n",
       "1555                     22              204.5               92   \n",
       "2691                      0              186.8               92   \n",
       "2119                      0              249.8              109   \n",
       "...                     ...                ...              ...   \n",
       "266                      28              225.8               94   \n",
       "67                        0              125.2               93   \n",
       "1575                     35              161.9               85   \n",
       "2315                      0              150.7               52   \n",
       "1917                      0              150.1              120   \n",
       "\n",
       "      total day charge  total eve calls  total eve charge  \\\n",
       "454              43.59              100             23.28   \n",
       "243              38.25               63             15.04   \n",
       "1555             34.77              121             11.87   \n",
       "2691             31.76              123             14.76   \n",
       "2119             42.47              106             20.60   \n",
       "...                ...              ...               ...   \n",
       "266              38.39              117             16.41   \n",
       "67               21.28              119             17.54   \n",
       "1575             27.52               82             12.85   \n",
       "2315             25.62               96             20.97   \n",
       "1917             25.52               85             17.01   \n",
       "\n",
       "      total night minutes  total night calls  total night charge  \\\n",
       "454                 222.7                101               10.02   \n",
       "243                 194.3                110                8.74   \n",
       "1555                205.0                103                9.23   \n",
       "2691                250.9                131               11.29   \n",
       "2119                231.8                 78               10.43   \n",
       "...                   ...                ...                 ...   \n",
       "266                 232.4                100               10.46   \n",
       "67                  129.3                139                5.82   \n",
       "1575                191.0                131                8.59   \n",
       "2315                103.8                118                4.67   \n",
       "1917                266.7                105               12.00   \n",
       "\n",
       "      total intl minutes  total intl calls  total intl charge  \\\n",
       "454                 11.1                 1               3.00   \n",
       "243                  7.1                 2               1.92   \n",
       "1555                 8.6                 5               2.32   \n",
       "2691                 9.7                 4               2.62   \n",
       "2119                11.6                 4               3.13   \n",
       "...                  ...               ...                ...   \n",
       "266                  8.4                 9               2.27   \n",
       "67                   8.3                 8               2.24   \n",
       "1575                 8.5                 2               2.30   \n",
       "2315                 7.0                 4               1.89   \n",
       "1917                11.0                 3               2.97   \n",
       "\n",
       "      customer service calls  international plan  \n",
       "454                        1                   0  \n",
       "243                        3                   0  \n",
       "1555                       2                   0  \n",
       "2691                       2                   0  \n",
       "2119                       0                   0  \n",
       "...                      ...                 ...  \n",
       "266                        4                   0  \n",
       "67                         0                   1  \n",
       "1575                       1                   0  \n",
       "2315                       2                   0  \n",
       "1917                       2                   0  \n",
       "\n",
       "[1000 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating feature data frame\n",
    "X_df = df.loc[idx,['number vmail messages','total day minutes','total day calls','total day charge','total eve calls','total eve charge','total night minutes','total night calls','total night charge','total intl minutes','total intl calls','total intl charge','customer service calls','international plan']]\n",
    "print(X_df.shape)\n",
    "X_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D) Creating the target dataframe, by converting it into numeric binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1555</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2315</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      churn\n",
       "454       1\n",
       "243       0\n",
       "1555      0\n",
       "2691      0\n",
       "2119      1\n",
       "...     ...\n",
       "266       0\n",
       "67        0\n",
       "1575      0\n",
       "2315      0\n",
       "1917      0\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating target dataframe\n",
    "#selecting the target for same index that we used to select feature\n",
    "y = churn_data.loc[idx,['churn']].astype(int)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we used `np.random.randint` function on our dataframe. \n",
    "- This function is used to select the random integers, which we used as our indexes to get the randomm records from our data. The purpose of doing that was, we don't want our model to fit and work on biased data. Hence, we provided random values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "### Split the data into 65% training data, 15% validation data, & 20% test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data\n",
    "- Here we split our dataframe into three sets, Train as 65% of data, Test as 20% of data and Validation as 15% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing train_test_split from sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#creating train and test dataset with train percentage as 80% and test percentage as 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df,y,random_state = 654,test_size=0.20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,random_state = 654,test_size=0.1875)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating train and test percentages and shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data percentage is 65.00 %\n",
      "Test data percentage is 20.00 %\n",
      "Test data percentage is 15.00 %\n",
      "\n",
      "\n",
      "Features train shape(650, 14)\n",
      "Features test shape(200, 14)\n",
      "Features validate shape(150, 14)\n",
      "\n",
      "\n",
      "Target train shape(650, 1)\n",
      "Target test shape(200, 1)\n",
      "Target validate shape(150, 1)\n"
     ]
    }
   ],
   "source": [
    "#Train data percentage\n",
    "print(\"Training data percentage is {:.2f}\".format(len(X_train)/len(X_df)*100)+\" %\")\n",
    "#Test data percentage\n",
    "print(\"Test data percentage is {:.2f}\".format((len(X_test)/len(X_df))*100)+\" %\")\n",
    "#Validation data percentage\n",
    "print(\"Validate data percentage is {:.2f}\".format((len(X_val)/len(X_df))*100)+\" %\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "#Tain, test,& validate feature dataset shapes\n",
    "print(\"Features train shape\"+str(X_train.shape))\n",
    "print(\"Features test shape\"+str(X_test.shape))\n",
    "print(\"Features validate shape\"+str(X_val.shape))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "#Tain, test,& validate target dataset shapes\n",
    "print(\"Target train shape\"+str(y_train.shape))\n",
    "print(\"Target test shape\"+str(y_test.shape))\n",
    "print(\"Target validate shape\"+str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 \n",
    "### Random Forest Classifier\n",
    "- ##### `RandomForestClassifier` from sklearn.ensemble \n",
    "- Building the Random forest model\n",
    "- Looping for all the values of number of trees using n_estimator parater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score for each fold for Random forest with number of trees as 5  is :[86.50306748 93.25153374 90.74074074 94.44444444]\n",
      "Train accuracy of the model is \t\t 91.23%\n",
      "Validation accuracy of the model is \t 90.67% \n",
      "\n",
      "\n",
      "Cross validation score for each fold for Random forest with number of trees as 7  is :[88.95705521 93.86503067 88.27160494 93.20987654]\n",
      "Train accuracy of the model is \t\t 91.08%\n",
      "Validation accuracy of the model is \t 93.33% \n",
      "\n",
      "\n",
      "Cross validation score for each fold for Random forest with number of trees as 9  is :[88.34355828 92.63803681 89.50617284 94.44444444]\n",
      "Train accuracy of the model is \t\t 91.23%\n",
      "Validation accuracy of the model is \t 92.00% \n",
      "\n",
      "\n",
      "Cross validation score for each fold for Random forest with number of trees as 11  is :[89.57055215 92.63803681 90.12345679 93.82716049]\n",
      "Train accuracy of the model is \t\t 91.54%\n",
      "Validation accuracy of the model is \t 92.67% \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#setting 4 folds\n",
    "cv_folds = 4\n",
    "\n",
    "#importing cross validation score and Random forest classifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#looping for all tree values\n",
    "for i in range (5,12,2):\n",
    "    \n",
    "    #creating object for random forest classifier\n",
    "    rf = RandomForestClassifier(n_estimators=i, random_state=654)\n",
    "    \n",
    "    #fitting the random forest classifier model on train data \n",
    "    rf.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    #calculating cross validation scores for 4 folds on train data\n",
    "    scores = cross_val_score(rf,X_train, y_train.values.ravel(),cv=cv_folds)\n",
    "    print(\"Cross validation score for each fold for Random forest with number of trees as {:d}  is :\".format(i)+str(scores*100))\n",
    "    \n",
    "    \n",
    "    model_accuracies = [round(num*100, 2) for num in scores]\n",
    "    \n",
    "    # calculating total accuracy of the model which the sum of folds accuracy by number of folds\n",
    "    train_accuracy = np.sum(model_accuracies)/cv_folds\n",
    "    print(\"Train accuracy of the model is \\t\\t {:.2f}%\".format(train_accuracy))\n",
    "    \n",
    "    \n",
    "    #calculating the score on validation dataset\n",
    "    print(\"Validation accuracy of the model is \\t {:.2f}% \\n\\n\".format(rf.score(X_val,y_val)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model with the best accuracy model with testing data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score for each fold for Random forest with number of trees as 11  is :[89.57055215 92.63803681 90.12345679 93.82716049]\n",
      "Train accuracy of the model is 91.54%\n",
      "Test accuracy of the model is 90.00% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#setting 4 folds\n",
    "cv_folds = 4\n",
    "\n",
    "#creating object for random forest classifier with model having best parameters\n",
    "rf = RandomForestClassifier(n_estimators=11, random_state=654)\n",
    "\n",
    "#fitting the random forest classifier model on train data \n",
    "rf.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "#calculating cross validation scores for 4 folds on train data\n",
    "scores = cross_val_score(rf,X_train, y_train.values.ravel(),cv=cv_folds)\n",
    "print(\"Cross validation score for each fold for Random forest with number of trees as {:d}  is :\".format(i)+str(scores*100))\n",
    "    \n",
    "\n",
    "model_accuracies = [round(num*100, 2) for num in scores]\n",
    "\n",
    "# calculating total accuracy of the model which the sum of folds accuracy by number of folds\n",
    "train_accuracy = np.sum(model_accuracies)/cv_folds\n",
    "print(\"Train accuracy of the model is {:.2f}%\".format(train_accuracy))\n",
    "    \n",
    "#calculating the score on test dataset\n",
    "print(\"Test accuracy of the model is {:.2f}% \\n\".format(rf.score(X_test,y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Explain the difference between the best accuracy obtained from the model and that obtained using the testing_set above.\n",
    "\n",
    "#### Compare your results in Step#1 above to the best results you had in lab #4, explain the differencies if any."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best accuracy obtained from the model has model train accuracy as `92.16%` and validation accuracy as `96%`, whereas accuracy obtained while checking the model with best parameters has same train accuracy but test accuracy is `90.50%` , which is low as compared to the validation accuracy.\n",
    "\n",
    "<p>\n",
    "This difference can be due to the model overfitting the data on evaluating using the validation data , also the reason being the validation score is more than train score, whereas on evaluating the data on test data the model is performing as expected and not overfitting the data. \n",
    "</p>\n",
    "\n",
    "On comparing the results with the best results in0 lab 4, we can see there is small difference between two.\n",
    "Here train and test accuracy is `92.16%` and `90.50%` where as in `lab 4` the best model accuracy was `96.00%` & `93.00%` for train and test respectively.\n",
    "This difference is due to the differnce between the model and the parameters, in lab 4 we were using DecisionTreeClassifier with best possible parameters and here we are using the RandomForest Classifier with different number of trees as paramter and with 4 cross folds.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Using nested loops use the GridSearchCV class with the model that you obtained in step 1 above, try to find the best combined parameters that provide the best accuracy for the testing dataset from:\n",
    "- max_depth values between 3 and 5 with a step of 1.\n",
    "- max_leaf_nodes values between 10 and 20 with a step of 5.\n",
    "- min_samples_leaf with values between 10 and 25 with a step of 5.\n",
    "\n",
    "\n",
    "- Plot your results for the testing and training accuracies for each step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing Grid search on the RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [3, 4, 5], 'max_leaf_nodes': [10, 15, 20], 'min_samples_leaf': [10, 15, 20, 25]}\n",
      "Train score is 90.0%\n",
      "Test score is 85.5% \n",
      "\n",
      "Best parameters are {'max_depth': 5, 'max_leaf_nodes': 15, 'min_samples_leaf': 10}\n",
      "Best grid search score is 86.92342649397864\n",
      "\n",
      "Best Estimator is RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=5, max_features='auto',\n",
      "                       max_leaf_nodes=15, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=10, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=11,\n",
      "                       n_jobs=None, oob_score=False, random_state=456,\n",
      "                       verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "#Creating paramter grid for different values as parameters for the model\n",
    "param_grid = {'max_depth':[3,4,5],\n",
    "              'max_leaf_nodes':[10,15,20],\n",
    "              'min_samples_leaf':[10,15,20,25]}\n",
    "print(param_grid)\n",
    "\n",
    "#importing the packages\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Creating grid search of the model for different parameters and the number of tree with the best accuracy parameter i.e. 11\n",
    "grid_search = GridSearchCV(RandomForestClassifier(n_estimators=11,random_state = 456),param_grid,cv=4,return_train_score = True)\n",
    "\n",
    "#fitting the train data\n",
    "grid_search.fit(X_train,y_train.values.ravel())\n",
    "\n",
    "#calculating train score\n",
    "train_score = round(grid_search.score(X_train,y_train.values.ravel())*100,2)\n",
    "print(\"Train score is \"+str(train_score)+\"%\")\n",
    "\n",
    "#calculating test score\n",
    "test_score = round(grid_search.score(X_test,y_test.values.ravel())*100,2)\n",
    "print(\"Test score is \"+str(test_score)+\"% \\n\")\n",
    "\n",
    "#finding the best parameters\n",
    "print(\"Best parameters are \"+str(grid_search.best_params_))\n",
    "\n",
    "#calculating best score of the model using best_score method\n",
    "print(\"Best grid search score is \"+str(grid_search.best_score_*100)+\"\\n\")\n",
    "\n",
    "#finding the best paramters\n",
    "print(\"Best Estimator is \"+str(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the train and test accuracies for the grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ4AAAFgCAYAAACL5B9mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de5xVdb3/8debGYQJFBkZEQUEExWEoBgv2UXMTE0TUjLRjmia+atOxzqdotIyTxc99kvNY5mXjLxkZiZ2TpZlFudkqaCoCJiKyEXQQS6KeAHmc/5Y36HtMMAGZ383zLyfj8d+zLqvz9oM+z3ru9b+LkUEZmZmuXSpdgFmZta5OHjMzCwrB4+ZmWXl4DEzs6wcPGZmlpWDx8zMsnLwbEckjZG0sNp1dBSSrpH0lWrXYdbZOHjeJEnzJL0iaZWkJZJ+IqlntevaUq2Oo+W1e8b9D5IUkmo3Mv/Kkrpel7SmZPzOrdlnRJwZEd9+c5VvHUnnldT/qqR1JeMPv4ntHitpTnvWatbeHDzt40MR0RMYBbwd+HKV69laH4qIniWvZ7dk5Y2FRnuIiLNb6gK+Dfy8pM6jc9bSHiLi30uO5zPA/5Qcz8hq11dJ2/q/jVWeg6cdRcQS4HcUAQSApGMkPSTpRUkLJJ1fMq/lr/yJkuZLWirpqyXz69IZ1HJJs4ADSvcnaaikP0laIekxSceVzPuJpB9IujP9Ff0XSbtJujRtb46kt5dzXJKOS9tfkfY3tGTePElfkvQI8LKkWkm7S/qlpCZJT0v6bMnyB0qalt6P5yR9L82amn6uSPW+s5zaSra7d3ovT5c0H7hLUhdJt6Yz0bZqv6Hl30PS+9OxfDHV/aykUzeyr49J+luraf8m6bY0fKyk2ZJekrRQ0ue25FhKtvk2Sfe0/PtL+lDJvOMlPZ72sUDSpyXtCvwC2Kfk7KlXG9s9QdIjad1nJH2p1fzDJd0vaWWa/9E0vaek/0z7a3k/u7R1lpV+lw9Ow9+VdL2kX0h6CRgv6b0l+3hW0v+XVFOy/tvT9pdLWizpHEl7pWPqWbLcoen/jj/LticR4debeAHzgPen4f7Ao8BlJfPHACMoQv5twHPAuDRvEBDA1UAdMBJ4DRia5l8I/A9QDwwAZgIL07yuwJPAV4AdgPcBLwH7pvk/AZYCo4HuwB+Bp4FTgRrgm8A9bR1Hq+PbB3gZOCLt84tpvzuUrDcj1VeXjnM68LVU117AXODItPxfgX9Kwz2Bg1u9F7VlvOfnAze0mrZ3Wv864C0ltZwG7Jjeg/8EppWscwNwfhp+P7AW+Ho6zuPSce/Uxv57AquAvUqmPQSMT8NNwCFpuB54x2aO50zgT62m7QwsAU5K/14HA8uAwYCAFcDotGwfYFQaPhaYs5n9HQEMTe9PI7Ccf/wO75uO7cNALbAr8LY0bzJwJ9A3zXtvqmWDfVL87rX8234XeBU4Ki1fl46nMR3bkPQ7cmZafhfgBeDs9DvUCzggzZva8vuTxq8GvlPtzwG/tuxV9QK29xfFB+8qig/9AO4Gdt7E8pcCl6Thlg/b/iXz7wdOSsNzgaNK5p3FP4LnPemDqUvJ/J+VfJD+BLi6ZN4/A7NLxkcAK9o4jhXpdXuafh5wS8lyXYBFwJiS9T5eMv8gYH6rY/4ycF0angp8A+jTapmW9+LNBs/ATazXJy3TI423Dp5VQE3J8suAxo1s62bgK2l4P2Al0D2NP0sRJjuW+TvUVvCcAdzZatqNwL9SfHgvpfgjomerZTYbPG3s/xrg39Pwt4Dr21imO7AOeGsb88oJnt9spoZzW/YLfIKi6bGt5c4AfpeGu1GE5rAtOV6/qv/y6Wn7GBcRO1Kc3exH8QEHgKSDUnNJk6SVFH/F9Wm1/pKS4dUUf1ED7A4sKJn3TMnw7sCCiGhuNX+PkvHnSoZfaWO89U0Q4yJi5/QaV7Kf9ftN+1vQaj+lNe4J7J6aYlZIWkFxVtY3zT+D4ixqjqQHJB1L+1pfi6QaSf8haa6kFynO1GDD97/F0ohYVzJe+m/R2k3AhDR8CnBbRLyaxj9MccY0PzUXHbQVx7En8L5W7+NYoF8Un7pjgY8CCyTdLekd5W44NXNNTc1hK4GP8Y/3ZADwVBur7U4ReE9vxbHAG39HkDRc0m9Tc+uLFL8jm6sBiqbEd0raDfgQMDciZm1lTVYlDp52FBF/pjjT+G7J5JuAO4ABEdELuJLiP3A5FlP8J2wxsGT4WWBAq7btgRRnI+3pWYoPQQAkKdVUup/SLs4XAE+XBNjOEbFjRHwQICKeiIgJFE04FwG3SurRahtbLX0otzgV+CBFM2QvirMiKP/935TfAntIGkERQDeV1HBfRBxHcYz/RXF2tKUWUJwllL6PPSPiC2kff4mIYygC/Y8UZ0NQ3vt4C8XZ3h7pd/IG/vGeLADe2sY6i9K2B7cx72WK5k0AJHWjaCos1bquaynO7veKiJ0obhjZXA1ExIvAryne838Crm9rOdu2OXja36XAEZJabjDYEVgWEa9KOhA4eQu2dQvwZUm9JfWnaC5rcR/Ff/gvSuoqaQzFX4Bb8yG3uRqOSRecu1I09bwG3LuR5e8HXlRxw0FdOusYLukAWH9hviGdOa1I66yjuC7STHFNqL3smGp9geKD8VvtteGIeB34JfA9irOiP8L6G0JOlrRTRKyhaIJdt/EtbdQvgQMljVdxw8YOkt6p4iaKHSWdKGlHYA1FE2HLPp4D+qYw30D6Q6UnxXvyuqR3AyeULDIZGKfihpIaSbtKGhERr1EE1PfTtJp05iRgVtrnGEk7ABeUcXw7UjT1vpzC+8ySebcBwySdlY67l6TGkvk/BT5J0Tx6E7bdcfC0s4hooviPcV6a9CnggnQ3z9coPsjL9Q2KZq6ngbso+esuffAdBxxN0Z7+A+DUiGjX73BExOMUTTGXp/18iOK269c3svy6tMyoVPdSimsILXdXHQU8JmkVcBnF9axXI2I1RTD8JTUtHdwO5V9Hccb2LPAYGw/LrXUTxYffz1s10U0EnklNSGdQ/GW+RSJiGXAkxfWOJRTHcAHFjQ9QXO9bQBHeJwGnp+nTKc7G5qf3sVer7TZTNPdeRnFd6vPArSXz/07RVPg1iusn91PciADwaWA+8DBFcJ0PKCKeAz4H/DzNn88//qjYmHOA/1fye7D+D6aIeIHiBoiPUfxBMhs4pGTd31ME158i4vnN7Me2QXpjy4SZ2bZP0v3A9yKivc/wLQOf8ZjZdkXSoRR3Qf6qyqXYVqpY8Ej6saTnJc0smVYv6feSnkg/e6fpkvR9SU+q+GJb2XfomFnnIelW4HbgM+m6k22HKnnG8xOK9vxSk4C7I2IIxfddJqXpR1N8iWwIRdv1DytYl5ltpyJifET0jogtuVZq25iKBU9ETKX4Al6psRR3zZB+jiuZ/tMo/A3YWVK/StVmZmbVk7uzvr4RsRggIhar6FsKii8jln7BbGGatrj1BiSdRXFWRI8ePUbvt99+la3YzKwM06dPXxoRDdWuY3uwrfQS29YX+tq83S4irgKuAmhsbIxp06ZVsi4zs7JIembzSxnkv6vtuZYmtPSz5R78hbzxG/r9Kb63YGZmHUzu4LmD4st1pJ9TSqafmu5uOxhY2dIkZ2ZmHUvFmtok/Yyi08w+Kh7X/HWKbv5vkXQGxbebP5IW/w1Fn1pPUnTMePoGGzQzsw6hkk+MnLCRWYe3sWxQdMdhZmYdnHsuMDOzrLaVu9rMzDqk6dOn71pbW3sNMJzO8cd+MzBz7dq1Z44ePbrNTlwdPGZmFVRbW3vNbrvtNrShoWF5ly5dOnyvzM3NzWpqahq2ZMmSayh60N9AZ0hfM7NqGt7Q0PBiZwgdgC5dukRDQ8NKijO8tpfJWI+ZWWfUpbOETot0vBvNFwePmZll5Ws8ZmYZDZr036Pbc3vzLjxm+qbmL1mypGbMmDH7AixdurRrly5dor6+fi3AjBkzZnfv3n2zZ2Pjx48fdN555y0eOXJkuzyKwsFjZtaB7bbbbuvmzJkzC+Dzn//87j179lx3wQUXPFe6THNzMxFBTU1Nm9u49dZb57VnTW5qMzPrhGbOnNltyJAh+5988skD999//2Hz58/vOmHChD2HDx8+dO+9997/C1/4wvpH04wePXrfe++9t27NmjXsuOOOoz71qU/tse+++w4bNWrUfosWLdriExgHj5lZJ/XUU091/+QnP7l09uzZswYPHrzm0ksvXThz5szZs2fPfuyee+7Zafr06d1br7Nq1aqaMWPGvPT444/PamxsXHXFFVf02dL9OnjMzDqpAQMGvHbooYeubhn/8Y9/XD9s2LCh+++//7C5c+d2f+SRR+par9O9e/fmE0888UWA0aNHr543b94OW7pfX+MxM+uk6urqmluGH3300W4/+tGP+k6bNm12nz591o0dO3bwK6+8ssGz0mpra9ffjFBTUxPr1q1r63lqm+QzHjMzY8WKFTU9evRY17t373XPPPNM16lTp+5UqX35jKeTu+yyy7j66quJCD7xiU9wzjnnsGzZMj760Y8yb948Bg0axC233ELv3r03WHfy5Ml885vfBODcc89l4sSJGyxjZm+0udufq+Vd73rX6iFDhry6zz777D9w4MDXRo8evapS+1LxRILtkx99/ebMnDmTk046ifvvv58ddtiBo446ih/+8IdcffXV1NfXM2nSJC688EKWL1/ORRdd9IZ1ly1bRmNjI9OmTUMSo0ePZvr06W0GlFlnIGl6RDS2nv7www/PGzly5NJq1FRNDz/8cJ+RI0cOamuem9o6sdmzZ3PwwQfzlre8hdraWg499FB+9atfMWXKlPVnLxMnTuT222/fYN3f/e53HHHEEdTX19O7d2+OOOIIfvvb3+Y+BDPbDjl4OrHhw4czdepUXnjhBVavXs1vfvMbFixYwHPPPUe/fsUt/P369eP55zfs2XzRokUMGDBg/Xj//v1ZtGhRttrNbPvlazyd2NChQ/nSl77EEUccQc+ePRk5ciS1teX9SrTVRCtt8c0tZtYJ+YynkzvjjDN48MEHmTp1KvX19QwZMoS+ffuyePFiABYvXsyuu+66wXr9+/dnwYIF68cXLlzI7rvvnq1uM9t+OXg6uZZmtPnz53PbbbcxYcIEjjvuOCZPngwUd66NHTt2g/WOPPJI7rrrLpYvX87y5cu56667OPLII7PWbmbbJze1dXInnHACL7zwAl27duWKK66gd+/eTJo0iRNPPJFrr72WgQMH8otf/AKAadOmceWVV3LNNddQX1/PeeedxwEHHADA1772Nerr66t5KGa2nfDt1GZm7aDs26nP79Wuj0Xg/JUVfywCwKWXXrrL8ccfv3LgwIFry1l+U7dT+4zHzKwDK+exCOW4/vrr+xx44IGryw2eTXHwmJl1UpdffvkuV1111a5r1qxRY2PjqsmTJ89vbm7mIx/5yOBZs2bVRYQmTpzY1Ldv3zWzZ89+y8knn/zW7t27N2/JmVJbOl3wDJr039UuwbYx8y48ptolmGX3wAMPdJ8yZcrODz744OyuXbsyYcKEPa+++ur6ffbZ57Vly5bV/v3vf58FsHTp0po+ffqsu/LKK3e9/PLL5x9yyCGvvNl9d7rgMTMzuPPOO3d65JFHeowYMWIYwKuvvtqlf//+r48bN27l3Llzu59++ukDjj322JUf/vCHX2zvfft2ajN7g0suuYT999+f4cOHM2HCBF599VVOO+00Bg8ezKhRoxg1ahQzZsxoc92ampr1yxx33HGZK7ctERFMmDBh6Zw5c2bNmTNn1rx582ZefPHFi3fbbbd1jz322GPvec97Vl1++eW7nnLKKXu29759xmNm6y1atIjvf//7zJo1i7q6Ok488URuvvlmAC6++GLGjx+/yfXr6uo2Gkq2bTn66KNfOvHEE986adKk5/v167d2yZIlNS+99FJNjx49muvq6po//vGPL997771f+9SnPrUnQI8ePZpffPHFmvbYt4PHzN5g7dq1vPLKK3Tt2pXVq1e7R4r2tpnbn3M58MADX5k0adKzhx122D7Nzc107do1fvCDHzxTU1PDJz7xiUERgSS+9a1vLQQ49dRTl5599tmD2uPmgk73PR7fXGCt+eaCN7rsssv46le/Sl1dHR/4wAe48cYbOe200/jrX/9Kt27dOPzww7nwwgvp1q3bBuvW1tYyatQoamtrmTRpEuPGjavCEVSHH4vwRn4sgpmVZfny5UyZMoWnn36aZ599lpdffpkbbriB73znO8yZM4cHHniAZcuWbfB8phbz589n2rRp3HTTTZxzzjk89dRTmY/AtgcOHjNb7w9/+AODBw+moaGBrl27cvzxx3PvvffSr18/JNGtWzdOP/107r///jbXb2mW22uvvRgzZgwPPfRQzvJtO+HgMbP1Bg4cyN/+9jdWr15NRHD33XczdOjQ9b2VRwS33347w4cP32Dd5cuX89prrwGwdOlS/vKXvzBs2LCs9W+jmpubmzvVM0PS8TZvbL6Dx8zWO+iggxg/fjzveMc7GDFiBM3NzZx11lmccsopjBgxghEjRrB06VLOPfdcoOg49swzzwSKJ9o2NjYycuRIDjvsMCZNmuTgKcxsamrq1VnCp7m5WU1NTb2AmRtbxjcXWKfnmwusPWzs5oLp06fvWltbew0wnM7xx34zMHPt2rVnjh49esPHF+Pbqc3MKip9+PrbtCU6Q/qamdk2xGc8Zuf3qnYFtq05f2W1K+jQfMZjZmZZOXjMzCwrB4+ZmWXl4DEzs6wcPGZmlpWDx8zMsnLwmJlZVg4eMzPLysFjZmZZOXjMzCwrB4+ZmWVVleCR9DlJj0maKelnkrpLGizpPklPSPq5pB2qUZuZmVVW9uCRtAfwWaAxIoYDNcBJwEXAJRExBFgOnJG7NjMzq7xqNbXVAnWSaoG3AIuB9wG3pvmTgXFVqs3MzCooe/BExCLgu8B8isBZCUwHVkTE2rTYQmCP3LWZmVnlVaOprTcwFhgM7A70AI5uY9E2n8kt6SxJ0yRNa2pqqlyhZmZWEdVoans/8HRENEXEGuA24BBg59T0BtAfeLatlSPiqohojIjGhoaGPBWbmVm7qUbwzAcOlvQWSQIOB2YB9wDj0zITgSlVqM3MzCqsGtd47qO4ieBB4NFUw1XAl4DPS3oS2AW4NndtZmZWebWbX6T9RcTXga+3mjwXOLAK5ZiZWUbuucDMzLJy8JiZWVYOHjMzy8rBY2ZmWTl4zMwsKwePmZll5eAxM7OsHDxmZpaVg8fMzLJy8JiZWVYOHjMzy8rBY2ZmWTl4zMwsKwePmZll5eAxM7OsHDxmZpaVg8fMzLJy8JiZWVYOHjMzy8rBY2ZmWTl4zMwsKwePmZll5eAxM7OsHDxmZpaVg8fMzLJy8JiZWVYOHjMzy8rBY2ZmWTl4zMwsKwePmZll5eAxM7OsHDxmZpaVg8fMzLJy8JiZWVYOHjMzy8rBY2ZmWTl4zMwsKwePmZll5eAxM7OsHDxmZpaVg8fMzLJy8JiZWVYOHjMzy8rBY2ZmWTl4zMwsKwePmZll5eAxM7OsHDxmZpaVg8fMzLJy8JiZWVZVCR5JO0u6VdIcSbMlvVNSvaTfS3oi/exdjdrMzKyyqnXGcxnw24jYDxgJzAYmAXdHxBDg7jRuZmYdTPbgkbQT8F7gWoCIeD0iVgBjgclpscnAuNy1mZlZ5VXjjGcvoAm4TtJDkq6R1APoGxGLAdLPXdtaWdJZkqZJmtbU1JSvajMzaxfVCJ5a4B3ADyPi7cDLbEGzWkRcFRGNEdHY0NBQqRrNzKxCqhE8C4GFEXFfGr+VIoiek9QPIP18vgq1mZlZhWUPnohYAiyQtG+adDgwC7gDmJimTQSm5K7NzMwqr7ZK+/1n4EZJOwBzgdMpQvAWSWcA84GPVKk2MzOroKoET0TMABrbmHV47lrMzCwv91xgZmZZOXjMzCwrB4+ZmWW12eCR9Bn3m2ZmZu2lnDOe3YAHJN0i6ShJqnRRZmbWcW02eCLiXGAIRd9qpwFPSPq2pLdWuDYzM+uAyrrGExEBLEmvtUBv4FZJ/1HB2szMrAPa7Pd4JH2WoieBpcA1wL9FxBpJXYAngC9WtkQzM+tIyvkCaR/g+Ih4pnRiRDRLOrYyZZmZWUdVTlPbb4BlLSOSdpR0EEBEzK5UYWZm1jGVEzw/BFaVjL+cppmZmW2xcoJH6eYCoGhio3qdi5qZ2XaunOCZK+mzkrqm179Q9ChtZma2xcoJnrOBQ4BFFA9xOwg4q5JFmZlZx7XZJrOIeB44KUMtZmbWCZTzPZ7uwBnA/kD3lukR8fEK1mVmZh1UOU1t11P013Yk8GegP/BSJYsyM7OOq5zg2TsizgNejojJwDHAiMqWZWZmHVU5wbMm/VwhaTjQCxhUsYrMzKxDK+f7OFel5/GcC9wB9ATOq2hVZmbWYW0yeFJHoC9GxHJgKrBXlqrMzKzD2mRTW+ql4DOZajEzs06gnGs8v5f0BUkDJNW3vCpemZmZdUjlXONp+b7Op0umBW52MzOzrVBOzwWDcxRiZmadQzk9F5za1vSI+Gn7l2NmZh1dOU1tB5QMdwcOBx4EHDxmZrbFymlq++fScUm9KLrRMTMz22Ll3NXW2mpgSHsXYmZmnUM513h+TXEXGxRBNQy4pZJFmZlZx1XONZ7vlgyvBZ6JiIUVqsfMzDq4coJnPrA4Il4FkFQnaVBEzKtoZWZm1iGVc43nF0Bzyfi6NM3MzGyLlRM8tRHxestIGt6hciWZmVlHVk7wNEk6rmVE0lhgaeVKMjOzjqycazxnAzdK+s80vhBoszcDMzOzzSnnC6RPAQdL6gkoIl6qfFlmZtZRbbapTdK3Je0cEasi4iVJvSV9M0dxZmbW8ZRzjefoiFjRMpKeRvrBypVkZmYdWTnBUyOpW8uIpDqg2yaWNzMz26hybi64Abhb0nVp/HRgcuVKMjOzjqycmwv+Q9IjwPsBAb8F9qx0YWZm1jGV2zv1EoreC06geB7P7IpVZGZmHdpGz3gk7QOcBEwAXgB+TnE79WGZajMzsw5oU01tc4D/AT4UEU8CSPpclqrMzKzD2lRT2wkUTWz3SLpa0uEU13jMzMy22kaDJyJ+FREfBfYD/gR8Dugr6YeSPpCpPjMz62A2e3NBRLwcETdGxLFAf2AGMKnilZmZWYdU7l1tAETEsoj4UUS8r1IFmZlZx7ZFwdOeJNVIekjSf6XxwZLuk/SEpJ9L8jN/zMw6oKoFD/AvvPH7QBcBl0TEEGA5cEZVqjIzs4qqSvBI6g8cA1yTxgW8D7g1LTIZGFeN2szMrLKqdcZzKfBFit4QAHYBVkTE2jS+ENijrRUlnSVpmqRpTU1Nla/UzMzaVfbgkXQs8HxETC+d3Mai0db6EXFVRDRGRGNDQ0NFajQzs8opp3fq9vYu4DhJHwS6AztRnAHtLKk2nfX0B56tQm1mZlZh2c94IuLLEdE/IgZR9AX3x4g4BbgHGJ8WmwhMyV2bmZlVXjXvamvtS8DnJT1Jcc3n2irXY2ZmFVCNprb1IuJPFN3xEBFzgQOrWY+ZmVXetnTGY2ZmnYCDx8zMsnLwmJlZVg4eMzPLysFjZmZZOXjMzCwrB4+ZmWXl4DEzs6wcPGZmlpWDx8zMsnLwmJlZVg4eMzPLysFjZmZZOXjMzCwrB4+ZmWXl4DEzs6wcPGZmlpWDx8zMsnLwmJlZVg4eMzPLysFjZmZZOXjMzCwrB4+ZmWXl4DEzs6wcPGZmlpWDx8zMsnLwmJlZVg4eMzPLysFjZmZZOXjMzCwrB4+ZmWXl4DEzs6wcPGZmlpWDx8zMsnLwmJlZVg4eMzPLysFjZmZZOXjMzCwrB4+ZmWXl4DEzs6wcPGZmlpWDx8zMsnLwmJlZVg4eMzPLysFjZmZZOXjMzCwrB4+ZmWXl4DEzs6wcPGZmllX24JE0QNI9kmZLekzSv6Tp9ZJ+L+mJ9LN37trMzKzyqnHGsxb414gYChwMfFrSMGAScHdEDAHuTuNmZtbBZA+eiFgcEQ+m4ZeA2cAewFhgclpsMjAud21mZlZ5Vb3GI2kQ8HbgPqBvRCyGIpyAXatXmZmZVUrVgkdST+CXwDkR8eIWrHeWpGmSpjU1NVWuQDMzq4iqBI+krhShc2NE3JYmPyepX5rfD3i+rXUj4qqIaIyIxoaGhjwFm5lZu6nGXW0CrgVmR8T3SmbdAUxMwxOBKblrMzOzyqutwj7fBfwT8KikGWnaV4ALgVsknQHMBz5ShdrMzKzCsgdPRPwvoI3MPjxnLWZmlp97LjAzs6wcPGZmlpWDx8zMsnLwmJlZVg4eMzPLysFjZmZZOXjMzCwrB4+ZmWXl4DEzs6wcPGZmlpWDx8zMsnLwmJlZVg4eMzPLysFjZmZZOXjMzCwrB4+ZmWXl4DEzs6wcPGZmlpWDx8zMsnLwmJlZVg4eMzPLysFjZmZZOXjMzCwrB4+ZmWXl4DEzs6wcPGZmlpWDx8zMsnLwmJlZVg4eMzPLysFjZmZZOXjMzCwrB4+ZmWXl4DEzs6wcPGZmlpWDx8zMsnLwmJlZVg4eMzPLysFjZmZZOXjMzCwrB4+ZmWXl4DEzs6wcPGZmlpWDx8zMsnLwmJlZVg4eMzPLysFjZmZZOXjMzCwrB4+ZmWXl4DEzs6wcPGZmltU2FTySjpL0uKQnJU2qdj1mZtb+tpngkVQDXAEcDQwDJkgaVt2qzMysvW0zwQMcCDwZEXMj4nXgZmBslWsyM7N2VlvtAkrsASwoGV8IHNR6IUlnAWel0VWSHs9Qm3Vggj7A0mrXYduQb2hr1tqzvcvoqLal4GnrXzo2mBBxFXBV5cuxzkLStIhorHYdZp3FttTUthAYUDLeH3i2SrWYmVmFbEvB8wAwRNJgSTsAJwF3VLkmMzNrZ9tMU1tErJX0GeB3QA3w44h4rMplWefgpluzjBSxwWUUMzOzitmWmtrMzKwTcPCYmVlWDh6rCknrJM2QNFPSryXt3E7bHSRpZjtt6yeSnk51zpD02fbY7kb2NUbSIZXavtm2xMFj1fJKRIyKiOHAMuDT1S5oI/4t1TkqIr5f7uD5U/0AAARdSURBVEqpC6gtMQZw8Fin4OCxbcFfKXquQFJPSXdLelDSo5LGpumDJM2WdLWkxyTdJakuzRst6WFJf6UkwCR1l3Rd2s5Dkg5L00+TdHs603pa0mckfT4t8zdJ9ZsqVtKEtM2Zki4qmb5K0gWS7gPemer6s6Tpkn4nqV9a7rOSZkl6RNLNkgYBZwOfS2dW72nH99Zs2xMRfvmV/QWsSj9rgF8AR6XxWmCnNNwHeJKiV4tBwFpgVJp3C/CxNPwIcGgavhiYmYb/FbguDe8HzAe6A6el7e4INAArgbPTcpcA56ThnwBPAzPSawSwe9pOQ6r1j8C4tHwAJ6bhrsC9QEMa/yjFVwSg+GJ0tzS8c/p5PvCFav+7+OVXjpfPeKxa6iTNAF4A6oHfp+kCvi3pEeAPFGdCfdO8pyNiRhqeDgyS1Iviw/vPafr1Jft4d8t4RMwBngH2SfPuiYiXIqKJInh+naY/ShFyLUqb2h4FDgD+FBFNEbEWuBF4b1p2HfDLNLwvMBz4fTrOcyl644AiKG+U9DGKMDXrVBw8Vi2vRMQoio4Vd+AfTWSnUJxNjE7zn6M4SwF4rWT9dRRnHKKNPv2STfX0WLqt5pLxZjb9xepNbfPViFhXstxjJaE1IiI+kOYdQ/EIkNHAdEnbzBe5zXJw8FhVRcRK4LPAFyR1BXoBz0fEmnRNZpM9/kbECmClpHenSaeUzJ7aMi5pH2Ag8GZ7M78POFRSn3QDwQTgz20s9zjQIOmdaf9dJe0vqQswICLuAb4I7Az0BF6iaPoz6/AcPFZ1EfEQ8DBF/3w3Ao2SplGExpwyNnE6cEW6ueCVkuk/AGokPQr8HDgtIl5rawNbUOti4MvAPanmByNiShvLvQ6MBy6S9DDFNaJDKK5p3ZBqegi4JIXnr4EP++YC6wzcZY6ZmWXlMx4zM8vKwWNmZlk5eMzMLCsHj5mZZeXgMTOzrBw81mFICknXl4zXSmqS9F9buJ15kvq82WXMrG0OHutIXgaGt3QeChwBLKpiPWbWBgePdTR3UnRJA0WvAj9rmSGpPvVK/UjqhfptafouqbfrhyT9iJJucSR9TNL96YudP9qKxx2YWSsOHutobgZOktQdeBtFFzctvgE8FBFvA74C/DRN/zrwvxHxduAOiq51kDSUolfpd6V+49bxxi55zGwruHNC61Ai4pH0fJsJwG9azX43cEJa7o/pTKcXRe/Sx6fp/y1peVr+cIqOPB+QBFAHPF/pYzDr6Bw81hHdAXyX4qmeu5RMb6tn6Wj1s5SAyRHx5XatzqyTc1ObdUQ/Bi5Iz88pVdpb9RhgaUS82Gr60UDvtPzdwHhJu6Z59ZI22Vu2mW2ez3isw4mIhcBlbcw6H7guPWRuNTAxTf8G8DNJD1I84mB+2s4sSecCd6XHGayheG7QM5U9ArOOzb1Tm5lZVm5qMzOzrBw8ZmaWlYPHzMyycvCYmVlWDh4zM8vKwWNmZlk5eMzMLKv/AzKQ0AK7wAeWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label = ['RandomForest']\n",
    "#print(label)\n",
    "\n",
    "\n",
    "x = np.arange(len(label))  \n",
    "width = 0.35  \n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 5))\n",
    "bar1 = ax.bar(x - width/2, train_score, width, label='Train')\n",
    "bar2 = ax.bar(x + width/2, test_score, width, label='Test')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_title('RandomForest Train vs Test accuracy')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(label)\n",
    "ax.set_ylim([0, 100])\n",
    "ax.legend(loc='center right', bbox_to_anchor=(1.25, 0.92))\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        #print(height)\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\")\n",
    "\n",
    "\n",
    "autolabel(bar1)\n",
    "autolabel(bar2)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On comparing the result with the best results of lab 4 we observe that, here the best parameter for grid search are 5,15,15 for max_depth, max_leaf_nodes, & min_samples_split respectively whereas in lab 4 the best paramters were 5,15,10 & 5,20,10 for  max_depth, max_leaf_nodes, & min_samples_split respectively.\n",
    "\n",
    "Also while comparing the best train and test accuracy, here best train and test accuracies are 91.69% & 86%, and in lab 4 it was 96% and 93%.\n",
    "The difference in accuracies is due to different models and parameters.\n",
    "\n",
    "Both have same parameters for Tree prunning but, here we are using RandomForest classifier with max trees as 11 and cross folds as 4, however there we were using DecisionTreeClassifier model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4- Explain how the GridSearchCV works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearchCV lets us combine an estimator with a grid search for parameter tunning. The method picks the optimal parameter from the grid search and uses it with the estimator.\n",
    "\n",
    "Example of the GridSearchCV is as show below:\n",
    "`grid_search = GridSearchCV(RandomForestClassifier(n_estimators=11,random_state = 456),param_grid,cv=4,return_train_score = True)`\n",
    "\n",
    "here we are creating an object `grid_search` for the GridSearchCV, GridSearchCV takes inputs as the model object with its parameters, here in out case it is `RandomForestClassifier(n_estimators=11,random_state = 456)` then the `param_grid` the structure in which we pass the variables and all the values associated with it on which model will work and then `cv` which specifies the number of folds and then `return_train_score` which will return the train score from thr function.\n",
    "\n",
    "With the help of GridSearch we can find out  best_score, best_parameters and best estimator for the model.\n",
    "\n",
    "prarm_grid/Grid search lets us create a structure that will include the variable names and the values, so instead of looping the model for each variables and their respective values we can use param_grid in the mode which will perform a grid operation on the model.\n",
    "\n",
    "here we are creating param_grid for parameter tunning in case of trees to prune the tree to avoid overfitting.\n",
    "Example\n",
    "\n",
    "param_grid = {'max_depth':[3,4,5],\n",
    "              'max_leaf_nodes':[10,15,20],\n",
    "              'min_samples_split':[10,15,20,25]}\n",
    "              \n",
    "We can also create use param_grid for different kernel values in case of SVM as parameters\n",
    "\n",
    "Example\n",
    "\n",
    "param_grid = [{'kernel':['rbf'],'c':[0.01,1,1000],\n",
    "              'gamma':[0.01,1,1000]},\n",
    "              {'kernel':['linear'],'c':[0.01,1,1000]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- Repeat questions 1 to 3 above using the XGBoost ensembel of your choice inplace of the random forest and compare your results. \n",
    "\n",
    "### Step 1\n",
    "### Building the XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score for each fold for XGBoost with number of trees as 5  is :[90.18404908 92.63803681 91.97530864 93.82716049]\n",
      "Train accuracy of the XGBoost model is \t\t 92.16%\n",
      "Validation accuracy of the  XGBoost model is \t 92.67% \n",
      "\n",
      "\n",
      "Cross validation score for each fold for XGBoost with number of trees as 7  is :[90.79754601 93.86503067 91.35802469 95.0617284 ]\n",
      "Train accuracy of the XGBoost model is \t\t 92.77%\n",
      "Validation accuracy of the  XGBoost model is \t 92.67% \n",
      "\n",
      "\n",
      "Cross validation score for each fold for XGBoost with number of trees as 9  is :[90.79754601 93.25153374 91.97530864 94.44444444]\n",
      "Train accuracy of the XGBoost model is \t\t 92.62%\n",
      "Validation accuracy of the  XGBoost model is \t 92.67% \n",
      "\n",
      "\n",
      "Cross validation score for each fold for XGBoost with number of trees as 11  is :[90.18404908 92.63803681 91.97530864 95.67901235]\n",
      "Train accuracy of the XGBoost model is \t\t 92.62%\n",
      "Validation accuracy of the  XGBoost model is \t 92.67% \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#setting 4 folds\n",
    "cv_folds = 4\n",
    "\n",
    "#importing cross validation score and xgboost\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost \n",
    "\n",
    "#looping for all tree values\n",
    "for i in range (5,12,2):\n",
    "    \n",
    "    #creating object for xgboost\n",
    "    xgb = xgboost.XGBClassifier(n_estimators=i, random_state=654)\n",
    "    \n",
    "    #fitting thexgboost model on train data \n",
    "    xgb.fit(X_train, y_train.values.ravel())\n",
    "    \n",
    "    #calculating cross validation scores for 4 folds on train data\n",
    "    scores = cross_val_score(xgb,X_train, y_train.values.ravel(),cv=cv_folds)\n",
    "    print(\"Cross validation score for each fold for XGBoost with number of trees as {:d}  is :\".format(i)+str(scores*100))\n",
    "    \n",
    "    \n",
    "    model_accuracies = [round(num*100, 2) for num in scores]\n",
    "    \n",
    "    # calculating total accuracy of the model which the sum of folds accuracy by number of folds\n",
    "    train_accuracy = np.sum(model_accuracies)/cv_folds\n",
    "    print(\"Train accuracy of the XGBoost model is \\t\\t {:.2f}%\".format(train_accuracy))\n",
    "    \n",
    "    \n",
    "    #calculating the score on validation dataset\n",
    "    print(\"Validation accuracy of the  XGBoost model is \\t {:.2f}% \\n\\n\".format(rf.score(X_val,y_val)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score for each fold for XGBoost with number of trees as 11  is :[90.18404908 92.63803681 91.97530864 95.67901235]\n",
      "Train accuracy of the XGBoost model is \t 92.62%\n",
      "Test accuracy of the XGBoost model is \t 94.50% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_folds = 4\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import xgboost\n",
    "\n",
    "\n",
    "xgb = xgboost.XGBClassifier(n_estimators=11, random_state=654)\n",
    "xgb.fit(X_train, y_train.values.ravel())\n",
    "scores = cross_val_score(xgb,X_train, y_train.values.ravel(),cv=cv_folds)\n",
    "print(\"Cross validation score for each fold for XGBoost with number of trees as {:d}  is :\".format(i)+str(scores*100))\n",
    "    \n",
    "model_accuracies = [round(num*100, 2) for num in scores]\n",
    "train_accuracy = np.sum(model_accuracies)/cv_folds\n",
    "print(\"Train accuracy of the XGBoost model is \\t {:.2f}%\".format(train_accuracy))\n",
    "    \n",
    "print(\"Test accuracy of the XGBoost model is \\t {:.2f}% \\n\".format(xgb.score(X_test,y_test)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "#### Grid search on xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [3, 4, 5], 'max_leaf_nodes': [10, 15, 20], 'min_samples_split': [10, 15, 20, 25]}\n",
      "Train score is 98.3076923076923%\n",
      "Test score is 94.0% \n",
      "\n",
      "\n",
      "Best parameters are {'max_depth': 5, 'max_leaf_nodes': 10, 'min_samples_split': 10}\n",
      "Best grid search score is 94.15568431417101\n",
      "\n",
      "\n",
      "Best Estimator is XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.300000012, max_delta_step=0, max_depth=5,\n",
      "              max_leaf_nodes=10, min_child_weight=1, min_samples_split=10,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=11, n_jobs=0,\n",
      "              num_parallel_tree=1, objective='binary:logistic',\n",
      "              random_state=654, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "              subsample=1, tree_method='exact', validate_parameters=1,\n",
      "              verbosity=0)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# xgboost only take mx_depth as paramter and gives warning for other parameters\n",
    "param_grid = {'max_depth':[3,4,5],\n",
    "              'max_leaf_nodes':[10,15,20],\n",
    "              'min_samples_split':[10,15,20,25]}\n",
    "print(param_grid)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost\n",
    "\n",
    "grid_search = GridSearchCV(xgboost.XGBClassifier(n_estimators=11, random_state=654,verbosity=0),param_grid,cv=4,return_train_score = True)\n",
    "grid_search.fit(X_train,y_train.values.ravel())\n",
    "print(\"Train score is \"+str(grid_search.score(X_train,y_train.values.ravel())*100)+\"%\")\n",
    "print(\"Test score is \"+str(grid_search.score(X_test,y_test.values.ravel())*100)+\"% \\n\\n\")\n",
    "print(\"Best parameters are \"+str(grid_search.best_params_))\n",
    "print(\"Best grid search score is \"+str(grid_search.best_score_*100)+\"\\n\\n\")\n",
    "print(\"Best Estimator is \"+str(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Grid search on GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [3, 4, 5], 'max_leaf_nodes': [10, 15, 20], 'min_samples_split': [10, 15, 20, 25]}\n",
      "Train score is 97.08%\n",
      "Test score is 90.5% \n",
      "\n",
      "Best parameters are {'max_depth': 5, 'max_leaf_nodes': 15, 'min_samples_split': 10}\n",
      "Best grid search score is 91.85033704461108\n",
      "\n",
      "Best Estimator is GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
      "                           learning_rate=0.1, loss='deviance', max_depth=5,\n",
      "                           max_features=None, max_leaf_nodes=15,\n",
      "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                           min_samples_leaf=1, min_samples_split=10,\n",
      "                           min_weight_fraction_leaf=0.0, n_estimators=11,\n",
      "                           n_iter_no_change=None, presort='deprecated',\n",
      "                           random_state=654, subsample=1.0, tol=0.0001,\n",
      "                           validation_fraction=0.1, verbose=0,\n",
      "                           warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_depth':[3,4,5],\n",
    "              'max_leaf_nodes':[10,15,20],\n",
    "              'min_samples_split':[10,15,20,25]}\n",
    "print(param_grid)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "grid_search = GridSearchCV(GradientBoostingClassifier(n_estimators=11, random_state=654),param_grid,cv=4,return_train_score = True)\n",
    "\n",
    "#fitting the train data\n",
    "grid_search.fit(X_train,y_train.values.ravel())\n",
    "\n",
    "#calculating train score\n",
    "train_score = round(grid_search.score(X_train,y_train.values.ravel())*100,2)\n",
    "print(\"Train score is \"+str(train_score)+\"%\")\n",
    "\n",
    "#calculating test score\n",
    "test_score = round(grid_search.score(X_test,y_test.values.ravel())*100,2)\n",
    "print(\"Test score is \"+str(test_score)+\"% \\n\")\n",
    "\n",
    "#finding the best parameters\n",
    "print(\"Best parameters are \"+str(grid_search.best_params_))\n",
    "\n",
    "#calculating best score of the model using best_score method\n",
    "print(\"Best grid search score is \"+str(grid_search.best_score_*100)+\"\\n\")\n",
    "\n",
    "#finding the best paramters\n",
    "print(\"Best Estimator is \"+str(grid_search.best_estimator_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the train and test accuracies for the grid search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label = ['XGBoost']\n",
    "#print(label)\n",
    "\n",
    "\n",
    "x = np.arange(len(label))  \n",
    "width = 0.35  \n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "bar1 = ax.bar(x - width/2, train_score, width, label='Train')\n",
    "bar2 = ax.bar(x + width/2, test_score, width, label='Test')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_title('XGBoost Train vs Test accuracy')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(label)\n",
    "ax.set_ylim([0, 100])\n",
    "ax.legend(loc='center right', bbox_to_anchor=(1.25, 0.92))\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        #print(height)\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),\n",
    "                    textcoords=\"offset points\")\n",
    "\n",
    "\n",
    "autolabel(bar1)\n",
    "autolabel(bar2)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
